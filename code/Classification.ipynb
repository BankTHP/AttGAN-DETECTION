{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cae20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay , mean_absolute_error\n",
    "from tensorflow.keras.losses import categorical_crossentropy, BinaryCrossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, InputLayer\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Nadam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f13bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('feature_df.csv')\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('combined_df.csv')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a009a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "\n",
    "inputs = feature_df\n",
    "target = combined_df['real']\n",
    "size_user = range(int(combined_df['user_id'].max()))\n",
    "\n",
    "#weight sample \n",
    "print(f'inputs size = {len(inputs)}')\n",
    "print(f'target size = {len(target)}')\n",
    "sample_weight = np.ones(shape=(len(target),))\n",
    "sample_weight[combined_df['attribute'] == 'lfw'] = 13\n",
    "print(f'sample size = {len(sample_weight)}')\n",
    "print(f'weight size per sample  = {Counter(sample_weight)}')\n",
    "\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "sample_count = 0\n",
    "acc_scores = []\n",
    "prec_scores = []\n",
    "rec_scores = []\n",
    "f1_scores = []\n",
    "for train, test in kfold.split(size_user):\n",
    "    \n",
    "    index_train = combined_df[combined_df['user_id'].isin(train)].index\n",
    "    index_test = combined_df[combined_df['user_id'].isin(test)].index\n",
    "    \n",
    "#     print(f'train {index_train}')\n",
    "#     print(f'test {index_test}')\n",
    "    \n",
    "#     print(f'train {len(index_train)}')\n",
    "#     print(f'test {len(index_test)}')\n",
    "    \n",
    "    \n",
    "    MLP_ = Sequential()\n",
    "    MLP_.add(InputLayer(input_shape=(2048, ))) \n",
    "    MLP_.add(Dense(64, activation='relu'))\n",
    "    MLP_.add(Dense(32, activation='relu'))# hidden layer 1\n",
    "    MLP_.add(Dense(2, activation='softmax')) # output layer\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    batch_size = 88\n",
    "    loss_function = sparse_categorical_crossentropy\n",
    "    no_epochs = 200\n",
    "    optimizer = Nadam()\n",
    "    verbosity = 1\n",
    "    \n",
    "\n",
    "    opt=tf.keras.optimizers.Nadam(learning_rate=0.0000001,name=\"Nadam\")\n",
    "\n",
    "  # Compile the model \n",
    "    MLP_.compile(loss=loss_function,optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    \n",
    "    print((inputs.iloc[index_train,:]).shape, (target.iloc[index_train]).shape)\n",
    "    print(len(inputs.iloc[index_train,:]), len(target.iloc[index_train]))\n",
    "    \n",
    "    history = MLP_.fit(inputs.iloc[index_train,:], target.iloc[index_train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,sample_weight=sample_weight[index_train])\n",
    "    \n",
    "    y_pred = MLP_.predict(inputs.iloc[index_test,:])\n",
    "    y_test = target.iloc[index_test].tolist()\n",
    "    result = []\n",
    "    for inner_list in y_pred:\n",
    "        if inner_list[0] > inner_list[1] :\n",
    "            result.append(0)\n",
    "        else :\n",
    "            result.append(1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    acc_scores.append(accuracy_score(y_test,result))\n",
    "    prec_scores.append(precision_score(y_test, result))\n",
    "    rec_scores.append(recall_score(y_test, result))\n",
    "    f1_scores.append(f1_score(y_test,result))\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", np.mean(acc_scores))\n",
    "    print(\"Precision:\", np.mean(prec_scores))\n",
    "    print(\"Recall:\", np.mean(rec_scores))\n",
    "    print(\"F1 score:\", np.mean(f1_scores))\n",
    "\n",
    "    \n",
    "    MLP_.save(f'All_attribute_{fold_no}.h5')\n",
    "\n",
    "  # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "\n",
    "# # == Provide average scores ==\n",
    "# print('------------------------------------------------------------------------')\n",
    "# print('Score per fold')\n",
    "# for i in range(0, len(acc_per_fold)):\n",
    "#     print('------------------------------------------------------------------------')\n",
    "#     print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "# print('------------------------------------------------------------------------')\n",
    "# print('Average scores for all folds:')\n",
    "# print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "# print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "# print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46701cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = target.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_ = keras.models.load_model('All_attribute_1.h5')\n",
    "test_predictions = MLP_.predict(inputs)\n",
    "result = []\n",
    "for inner_list in test_predictions:\n",
    "        if inner_list[0] > inner_list[1] :\n",
    "            result.append(0)\n",
    "        else :\n",
    "            result.append(1)\n",
    "print('epochs 200 + layer')\n",
    "recall_score = recall_score(result,target_list, average='macro')\n",
    "print('recall',recall_score)\n",
    "f1_macro = f1_score(result,target, average='macro')\n",
    "print(\"F1 score (macro):\", f1_macro)\n",
    "print('mean_absolute_error',mean_absolute_error(result,target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(result,target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(target_list, result)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
