{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89fa35f",
   "metadata": {},
   "source": [
    "# Import and install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdfbd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/rcmalli/keras-vggface.git\n",
    "!conda install -c conda-forge keras-applications -y\n",
    "!conda install -c conda-forge mtcnn -y\n",
    "!conda install -c conda-forge keras -y\n",
    "!conda install -c conda-forge tensorflow -y\n",
    "!pip install keras-vggface\n",
    "!pip install sklearn\n",
    "!pip install keras_vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe79709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb721fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_input_vgg16\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa2497",
   "metadata": {},
   "source": [
    "# Datasets and Assign ID to dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e550a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTE_NAME = ['Bald','Bangs','Black_Hair','Blond_Hair','Brown_Hair','Bushy_Eyebrows','Eyeglasses','Male','Mouth_Slightly_Open','Mustache','No_Beard','Pale_Skin','Young'] #Attribute name from lfwa+ dataset\n",
    "EXTRACT_NAME = 'ResNet50' #model to feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5cc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTE_NAME.sort() # sort for correct ordering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path1 = '/Users/bankthp/Downloads/GAN-DETECTION/crop_0to1/custom_testing_slide_{}/8'.format(ATTRIBUTE_NAME[0]) #path the generated image 0 to 1 \n",
    "img_path2 = '/Users/bankthp/Downloads/GAN-DETECTION/crop_1to0/custom_testing_slide_{}/8'.format(ATTRIBUTE_NAME[0]) #path the generated image 1 to 0\n",
    "\n",
    "pic0 = os.listdir(img_path1)\n",
    "pic1 = os.listdir(img_path2)\n",
    "\n",
    "pic0_size = round(len(pic0))\n",
    "pic1_size = round(len(pic1))\n",
    "\n",
    "\n",
    "pic_size = len(pic0+pic1)\n",
    "all_pic = pic0+pic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pic.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea43acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_path = '/Users/bankthp/Downloads/GAN-DETECTION/lfw' #lfw path \n",
    "lfw_name = os.listdir('/Users/bankthp/Downloads/LFWA+/lfw') #lfw_name folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721dcff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_name.remove('.ipynb_checkpoints')\n",
    "lfw_name.remove('.DS_Store')\n",
    "lfw_name.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_ids = range(len(all_pic))\n",
    "pic_to_id = dict(zip(all_pic, pic_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = range(len(lfw_name))\n",
    "name_to_id = dict(zip(lfw_name, ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f584eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('userID.txt', 'w') as file:\n",
    "     file.write(json.dumps(name_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0922b3d",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ebd256",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractResNet = ResNet50(weights='imagenet',include_top=False,pooling=\"avg\")\n",
    "model = extractResNet\n",
    "\n",
    "img_path = img_path1+\"/\"+pic0[0]\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in ATTRIBUTE_NAME :\n",
    "    print(attr)\n",
    "    \n",
    "    img_path1 = '/Users/bankthp/Downloads/GAN-DETECTION/crop_0to1/custom_testing_slide_{}/8'.format(attr)\n",
    "    img_path2 = '/Users/bankthp/Downloads/GAN-DETECTION/crop_1to0/custom_testing_slide_{}/8'.format(attr)\n",
    "\n",
    "    pic0 = os.listdir(img_path1)\n",
    "    pic1 = os.listdir(img_path2)\n",
    "\n",
    "    pic0_size = round(len(pic0))\n",
    "    pic1_size = round(len(pic1))\n",
    "\n",
    "\n",
    "    pic_size = len(pic0+pic1)\n",
    "    \n",
    "    all_pic = pic0+pic1\n",
    "    \n",
    "    lfw_path = '/Users/bankthp/Downloads/GAN-DETECTION/lfw'\n",
    "    lfw_photo = os.listdir(lfw_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    size = len(all_pic)\n",
    "    \n",
    "    lfw_name = os.listdir('/Users/bankthp/Downloads/LFWA+/lfw')\n",
    "    \n",
    "    for name_list in [lfw_name, all_pic, lfw_photo]:\n",
    "        if '.ipynb_checkpoints' in name_list:\n",
    "            name_list.remove('.ipynb_checkpoints')\n",
    "        if '.DS_Store' in name_list:\n",
    "            name_list.remove('.DS_Store')\n",
    "        \n",
    "        \n",
    "    lfw_name.sort()\n",
    "    all_pic.sort()\n",
    "    lfw_photo.sort()\n",
    "    \n",
    "    ids = range(len(lfw_name))\n",
    "    name_to_id = dict(zip(lfw_name, ids))\n",
    "    \n",
    "    pic_ids = range(len(lfw_photo))\n",
    "    pic_to_id = dict(zip(lfw_photo, pic_ids))\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    feature = np.empty([size,features.shape[1]])\n",
    "\n",
    "    train = pd.DataFrame({\n",
    "        'user_id': np.zeros(size),\n",
    "        'pic_id' : np.zeros(size),\n",
    "        'pic_name' : np.empty((size),dtype=object),\n",
    "        'attribute': np.empty((size), dtype=object),\n",
    "        'real' : np.zeros(size)\n",
    "    })\n",
    "\n",
    "\n",
    "    for i in range(size) :\n",
    "        \n",
    "        #assgin dict id to train['user_id']\n",
    "        name_no_ext = os.path.splitext(all_pic[i])[0]\n",
    "        name_parts = name_no_ext.split('_')\n",
    "\n",
    "        for j in range(len(name_parts)):\n",
    "            sub_name = '_'.join(name_parts[:len(name_parts)-j])\n",
    "            if sub_name in name_to_id:\n",
    "                matched_name = sub_name\n",
    "                break\n",
    "\n",
    "        if matched_name:\n",
    "            id_num = name_to_id[matched_name]\n",
    "            train['user_id'][i] = id_num\n",
    "        else:\n",
    "            print(\"No match found\")\n",
    "            \n",
    "        \n",
    "        #assgin dict id to train['user_id']\n",
    "\n",
    "        # check if the key \"banana\" exists in the dictionary\n",
    "        if all_pic[i] in pic_to_id :\n",
    "            train['pic_id'][i]= pic_to_id.get(all_pic[i])\n",
    "        \n",
    "            \n",
    "            \n",
    "        train['pic_name'][i] = all_pic[i]\n",
    "        train['attribute'][i] = attr  \n",
    "        train['real'][i] = 0\n",
    "        feature[count,:] = model.predict(x)\n",
    "\n",
    "        count = count + 1 \n",
    "            \n",
    "            \n",
    "    train.to_csv('{}.csv'.format(attr),index=False)\n",
    "    np.savetxt('feature_lfw.csv', feature, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57d401",
   "metadata": {},
   "source": [
    "# LFW Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_path = '/Users/bankthp/Downloads/GAN-DETECTION/lfw'\n",
    "lfw_photo = os.listdir(lfw_path)\n",
    "    \n",
    "size = len(all_pic)\n",
    "    \n",
    "lfw_name = os.listdir('/Users/bankthp/Downloads/LFWA+/lfw')\n",
    "    \n",
    "for name_list in [lfw_name, all_pic, lfw_photo]:\n",
    "    if '.ipynb_checkpoints' in name_list:\n",
    "        name_list.remove('.ipynb_checkpoints')\n",
    "    if '.DS_Store' in name_list:\n",
    "        name_list.remove('.DS_Store')\n",
    "        \n",
    "        \n",
    "lfw_name.sort()\n",
    "all_pic.sort()\n",
    "lfw_photo.sort()\n",
    "    \n",
    "ids = range(len(lfw_name))\n",
    "name_to_id = dict(zip(lfw_name, ids))\n",
    "    \n",
    "pic_ids = range(len(lfw_photo))\n",
    "pic_to_id = dict(zip(lfw_photo, pic_ids))\n",
    "    \n",
    "    \n",
    "count = 0\n",
    "    \n",
    "size = len(lfw_photo)\n",
    "\n",
    "feature = np.empty([size,features.shape[1]])\n",
    "\n",
    "train = pd.DataFrame({\n",
    "    'user_id': np.zeros(size),\n",
    "    'pic_id' : np.zeros(size),\n",
    "    'pic_name' : np.empty((size),dtype=object),\n",
    "    'attribute': np.empty((size), dtype=object),\n",
    "    'real' : np.zeros(size)\n",
    "})\n",
    "\n",
    "\n",
    "for i in range(size) :\n",
    "        \n",
    "    #assgin dict id to train['user_id']\n",
    "    name_no_ext = os.path.splitext(lfw_photo[i])[0]\n",
    "    name_parts = name_no_ext.split('_')\n",
    "\n",
    "    for j in range(len(name_parts)):\n",
    "        sub_name = '_'.join(name_parts[:len(name_parts)-j])\n",
    "        if sub_name in name_to_id:\n",
    "            matched_name = sub_name\n",
    "            break\n",
    "\n",
    "    if matched_name:\n",
    "        id_num = name_to_id[matched_name]\n",
    "        train['user_id'][i] = id_num\n",
    "    else:\n",
    "        print(\"No match found\")\n",
    "            \n",
    "        \n",
    "    #assgin dict id to train['pic_id']\n",
    "    if all_pic[i] in pic_to_id :\n",
    "        train['pic_id'][i]= pic_to_id.get(lfw_photo[i])\n",
    "        \n",
    "            \n",
    "            \n",
    "    train['pic_name'][i] = lfw_photo[i]\n",
    "    train['attribute'][i] = 'lfw'  \n",
    "    train['real'][i] = 0\n",
    "    feature[count,:] = model.predict(x)\n",
    "\n",
    "    count = count + 1 \n",
    "            \n",
    "            \n",
    "train.to_csv('lfw.csv',index=False)\n",
    "np.savetxt('feature_lfw.csv', feature, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
